{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80d7efbb-b7b4-4562-acd0-e57dcf4f603b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Preview:\n",
      "                  City  Gender            Product line  Unit price  Quantity  \\\n",
      "Invoice ID                                                                     \n",
      "750-67-8428     Yangon  Female       Health and beauty       74.69         7   \n",
      "226-31-3081  Naypyitaw  Female  Electronic accessories       15.28         5   \n",
      "631-41-3108     Yangon    Male      Home and lifestyle       46.33         7   \n",
      "123-19-1176     Yangon    Male       Health and beauty       58.22         8   \n",
      "373-73-7910     Yangon    Male       Sports and travel       86.31         7   \n",
      "\n",
      "                Total       Date      Payment  gross income  Rating  \n",
      "Invoice ID                                                           \n",
      "750-67-8428  548.9715   1/5/2019      Ewallet       26.1415     9.1  \n",
      "226-31-3081   80.2200   3/8/2019         Cash        3.8200     9.6  \n",
      "631-41-3108  340.5255   3/3/2019  Credit card       16.2155     7.4  \n",
      "123-19-1176  489.0480  1/27/2019      Ewallet       23.2880     8.4  \n",
      "373-73-7910  634.3785   2/8/2019      Ewallet       30.2085     5.3  \n",
      "\n",
      "QA Dataset Preview:\n",
      "                                            question  \\\n",
      "0          What product line is in the latest entry?   \n",
      "1      On what date did the first transaction occur?   \n",
      "2               What is the latest transaction date?   \n",
      "3  what is the max rating given in home and lifes...   \n",
      "4  How many transactions involved Male customers ...   \n",
      "\n",
      "                                           row index column index  \\\n",
      "0                                                999            3   \n",
      "1  17, 245, 450, 484, 496, 523, 567, 696, 829, 83...            7   \n",
      "2  158, 306, 473, 474, 643, 646, 671, 881, 883, 9...            7   \n",
      "3  2, 7, 19, 22, 25, 39, 40, 41, 54, 56, 58, 61, ...         3,10   \n",
      "4                            331, 464, 540, 708, 710         2,10   \n",
      "\n",
      "                answer  filtered row index  filtered column index  \\\n",
      "0  Fashion accessories                 NaN                    NaN   \n",
      "1             1/1/2019                 NaN                    NaN   \n",
      "2            3/30/2019                 NaN                    NaN   \n",
      "3                  9.9                 NaN                    NaN   \n",
      "4                    5                 NaN                    NaN   \n",
      "\n",
      "   generated response  \n",
      "0                 NaN  \n",
      "1                 NaN  \n",
      "2                 NaN  \n",
      "3                 NaN  \n",
      "4                 NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load tabular dataset\n",
    "table = pd.read_csv('input_table.csv',header=0,index_col=0)     # <-- Your main data\n",
    "\n",
    "# (Optional) Load QA dataset (for testing, if available)\n",
    "qa_data = pd.read_excel('QA_dataset_share.xlsx')        # <-- Questions & answers\n",
    "\n",
    "# Show preview\n",
    "print(\"Table Preview:\")\n",
    "print(table.head())\n",
    "\n",
    "print(\"\\nQA Dataset Preview:\")\n",
    "print(qa_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ada8df-3909-4a99-9ce0-e71325ad92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aebdd9f-ce6c-4917-97fd-75f148c70ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in d:\\anaconda\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (0.32.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d57af0e-f81b-4721-a55f-19855e751964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After restarting the kernel, run this cell:\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # free, fast, small\n",
    "\n",
    "def get_relevant_rows_and_cols(query, df, top_n=5):\n",
    "    # Flatten table text for column-level matching\n",
    "    column_texts = df.columns.tolist()\n",
    "    row_texts = df.astype(str).apply(lambda x: ' '.join(x), axis=1).tolist()\n",
    "\n",
    "    # Embed everything\n",
    "    query_emb = model.encode(query, convert_to_tensor=True)\n",
    "    row_embs = model.encode(row_texts, convert_to_tensor=True)\n",
    "    col_embs = model.encode(column_texts, convert_to_tensor=True)\n",
    "\n",
    "    # Compute similarity\n",
    "    row_scores = util.pytorch_cos_sim(query_emb, row_embs)[0]\n",
    "    col_scores = util.pytorch_cos_sim(query_emb, col_embs)[0]\n",
    "\n",
    "    # Get top N\n",
    "    top_row_indices = row_scores.topk(top_n).indices.tolist()\n",
    "    top_col_indices = col_scores.topk(top_n).indices.tolist()\n",
    "\n",
    "    return top_row_indices, top_col_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d8602c3-28b5-4401-961c-405a9b6d0ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in d:\\anaconda\\envs\\tabuquestvenv\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers in d:\\anaconda\\envs\\tabuquestvenv\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\anaconda\\envs\\tabuquestvenv\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\anaconda\\envs\\tabuquestvenv\\lib\\site-packages (from sentence-transformers) (0.32.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\anaconda\\envs\\tabuquestvenv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\anaconda\\envs\\tabuquestvenv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\envs\\tabuquestvenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\anaconda\\envs\\tabuquestvenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\envs\\tabuquestvenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\envs\\tabuquestvenv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sentence-transformers transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a99d66-730c-499f-9e50-8c49a3acb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # free, fast, small\n",
    "\n",
    "def get_relevant_rows_and_cols(query, df, top_n=5):\n",
    "    # Flatten table text for column-level matching\n",
    "    column_texts = df.columns.tolist()\n",
    "    row_texts = df.astype(str).apply(lambda x: ' '.join(x), axis=1).tolist()\n",
    "\n",
    "    # Embed everything\n",
    "    query_emb = model.encode(query, convert_to_tensor=True)\n",
    "    row_embs = model.encode(row_texts, convert_to_tensor=True)\n",
    "    col_embs = model.encode(column_texts, convert_to_tensor=True)\n",
    "\n",
    "    # Compute similarity\n",
    "    row_scores = util.pytorch_cos_sim(query_emb, row_embs)[0]\n",
    "    col_scores = util.pytorch_cos_sim(query_emb, col_embs)[0]\n",
    "\n",
    "    # Get top N\n",
    "    top_row_indices = row_scores.topk(top_n).indices.tolist()\n",
    "    top_col_indices = col_scores.topk(top_n).indices.tolist()\n",
    "\n",
    "    return top_row_indices, top_col_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe9729d5-52b3-415c-981d-e3f410e1ae6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU if available, otherwise CPU\n",
    "\n",
    "# Create QA pipeline with explicit device placement\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\", \n",
    "    model=\"distilbert-base-uncased-distilled-squad\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "def generate_answer(query, df, row_indices=None, col_indices=None, max_context_length=512):\n",
    "    \"\"\"\n",
    "    Generate answers to questions based on DataFrame content.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The question to answer\n",
    "        df (pd.DataFrame): Source DataFrame containing the data\n",
    "        row_indices (list, optional): Specific rows to include. If None, use all rows.\n",
    "        col_indices (list, optional): Specific columns to include. If None, use all columns.\n",
    "        max_context_length (int, optional): Maximum context length to avoid token limits\n",
    "        \n",
    "    Returns:\n",
    "        dict: Full result dictionary with answer, score, and positions\n",
    "    \"\"\"\n",
    "    # Handle default indices\n",
    "    row_indices = row_indices if row_indices is not None else range(len(df))\n",
    "    col_indices = col_indices if col_indices is not None else df.columns\n",
    "    \n",
    "    # Extract context (filtered data)\n",
    "    filtered_df = df.iloc[row_indices, col_indices]\n",
    "    context = filtered_df.to_string(index=False)\n",
    "    \n",
    "    # Truncate context if too long (to avoid token limits)\n",
    "    if len(context) > max_context_length:\n",
    "        context = context[:max_context_length]\n",
    "    \n",
    "    # Ask question\n",
    "    result = qa_pipeline(question=query, context=context)\n",
    "    \n",
    "    # Return full result for more information\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c178773-91d0-4cc2-af5b-a3882a5baa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "def generate_output(query, df):\n",
    "    rows, cols = get_relevant_rows_and_cols(query, df)\n",
    "    answer = generate_answer(query, df, rows, cols)\n",
    "\n",
    "    output_df = pd.DataFrame({\n",
    "        'filtered row index': [rows],\n",
    "        'filtered column index': [cols],\n",
    "        'generated response': [answer]\n",
    "    })\n",
    "\n",
    "    output_df.to_excel('predicted.xlsx', index=False)\n",
    "    return output_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3479a6c3-f0aa-4f03-981b-bad8f7c69d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Step 1: Table Loaded\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Step 1: Table Loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Step 2: Retriever Output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mrows\u001b[49m, cols)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Step 3: Generated Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m, answer)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Step 4: Output saved to predicted.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rows' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"✅ Step 1: Table Loaded\")\n",
    "print(\"✅ Step 2: Retriever Output:\", rows, cols)\n",
    "print(\"✅ Step 3: Generated Response:\", answer)\n",
    "print(\"✅ Step 4: Output saved to predicted.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02387681-c29e-4fb0-bdff-4f17103541fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: [749, 141, 426, 523, 14]\n",
      "Cols: [9, 6, 10, 2, 5]\n",
      "Answer: {'score': 0.02001830004155636, 'start': 102, 'end': 143, 'answer': '45.2500 950.2500     8.1   Male        10'}\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library first\n",
    "import pandas as pd\n",
    "\n",
    "# Define the table variable\n",
    "table = pd.read_csv('input_table.csv')  # Replace this with your actual table data\n",
    "# For example:\n",
    "# table = pd.read_csv('your_data.csv')\n",
    "# OR\n",
    "# table = pd.DataFrame({'Category': ['Health and Beauty', 'Electronics', ...],\n",
    "#                      'Gross Income': [1500, 2000, ...]})\n",
    "\n",
    "query = \"What is the highest gross income for health and beauty?\"\n",
    "rows, cols = get_relevant_rows_and_cols(query, table)\n",
    "answer = generate_answer(query, table, rows, cols)\n",
    "\n",
    "print(\"Rows:\", rows)\n",
    "print(\"Cols:\", cols)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f07d3b8-a392-4b69-a125-7bc88ed1d46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: [312, 727, 590, 426, 589]\n",
      "Cols: [10, 6, 2, 4, 5]\n",
      "Answer: {'score': 0.13640296459197998, 'start': 50, 'end': 69, 'answer': '4.4  74.7075 Female'}\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library first\n",
    "import pandas as pd\n",
    "\n",
    "# Define the table variable\n",
    "table = pd.read_csv('input_table.csv')  # Replace this with your actual table data\n",
    "# For example:\n",
    "# table = pd.read_csv('your_data.csv')\n",
    "# OR\n",
    "# table = pd.DataFrame({'Category': ['Health and Beauty', 'Electronics', ...],\n",
    "#                      'Gross Income': [1500, 2000, ...]})\n",
    "\n",
    "query = \"What is highest rating?\"\n",
    "rows, cols = get_relevant_rows_and_cols(query, table)\n",
    "answer = generate_answer(query, table, rows, cols)\n",
    "\n",
    "print(\"Rows:\", rows)\n",
    "print(\"Cols:\", cols)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b62a2ae5-da95-4fba-b070-111d3ec193c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: [540, 416, 253, 268, 22]\n",
      "Cols: [10, 6, 9, 4, 5]\n",
      "Answer: {'score': 0.0526006706058979, 'start': 56, 'end': 59, 'answer': '9.1'}\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library first\n",
    "import pandas as pd\n",
    "\n",
    "# Define the table variable\n",
    "table = pd.read_csv('input_table.csv')  # Replace this with your actual table data\n",
    "# For example:\n",
    "# table = pd.read_csv('your_data.csv')\n",
    "# OR\n",
    "# table = pd.DataFrame({'Category': ['Health and Beauty', 'Electronics', ...],\n",
    "#                      'Gross Income': [1500, 2000, ...]})\n",
    "\n",
    "query = \"what is the max rating given in home and lifestyle?\"\n",
    "rows, cols = get_relevant_rows_and_cols(query, table)\n",
    "answer = generate_answer(query, table, rows, cols)\n",
    "\n",
    "print(\"Rows:\", rows)\n",
    "print(\"Cols:\", cols)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7aa2a4d8-c716-47cb-bcbb-305d88b900bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: [12, 811, 782, 655, 549]\n",
      "Cols: [3, 7, 4, 5, 6]\n",
      "Answer: {'score': 0.7685032486915588, 'start': 64, 'end': 86, 'answer': 'Electronic accessories'}\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library first\n",
    "import pandas as pd\n",
    "\n",
    "# Define the table variable\n",
    "table = pd.read_csv('input_table.csv')  # Replace this with your actual table data\n",
    "# For example:\n",
    "# table = pd.read_csv('your_data.csv')\n",
    "# OR\n",
    "# table = pd.DataFrame({'Category': ['Health and Beauty', 'Electronics', ...],\n",
    "#                      'Gross Income': [1500, 2000, ...]})\n",
    "\n",
    "query = \"What product line is in the latest entry?\"\n",
    "rows, cols = get_relevant_rows_and_cols(query, table)\n",
    "answer = generate_answer(query, table, rows, cols)\n",
    "\n",
    "print(\"Rows:\", rows)\n",
    "print(\"Cols:\", cols)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "482215e2-11a1-4653-88e9-64dc0a2ad94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: [655, 369, 303, 674, 549]\n",
      "Cols: [2, 6, 3, 4, 5]\n",
      "Answer: {'score': 0.8057325482368469, 'start': 64, 'end': 86, 'answer': 'Electronic accessories'}\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library first\n",
    "import pandas as pd\n",
    "\n",
    "# Define the table variable\n",
    "table = pd.read_csv('input_table.csv',index_col=0)  # Replace this with your actual table data\n",
    "# For example:\n",
    "# table = pd.read_csv('your_data.csv')\n",
    "# OR\n",
    "# table = pd.DataFrame({'Category': ['Health and Beauty', 'Electronics', ...],\n",
    "#                      'Gross Income': [1500, 2000, ...]})\n",
    "\n",
    "query = \"What product line is in the latest entry?\"\n",
    "rows, cols = get_relevant_rows_and_cols(query, table)\n",
    "answer = generate_answer(query, table, rows, cols)\n",
    "\n",
    "print(\"Rows:\", rows)\n",
    "print(\"Cols:\", cols)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "defaf972-c904-4151-8230-77bc6c04fbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: [174, 28, 734, 638, 724]\n",
      "Cols: [5, 3, 4, 6, 7]\n",
      "Answer: {'score': 0.6045435070991516, 'start': 70, 'end': 88, 'answer': 'Food and beverages'}\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library first\n",
    "import pandas as pd\n",
    "\n",
    "# Define the table variable\n",
    "table = pd.read_csv('input_table.csv')  # Replace this with your actual table data\n",
    "# For example:\n",
    "# table = pd.read_csv('your_data.csv')\n",
    "# OR\n",
    "# table = pd.DataFrame({'Category': ['Health and Beauty', 'Electronics', ...],\n",
    "#                      'Gross Income': [1500, 2000, ...]})\n",
    "\n",
    "query = \"which product  is most sold in mandalay as per quantity?\"\n",
    "rows, cols = get_relevant_rows_and_cols(query, table)\n",
    "answer = generate_answer(query, table, rows, cols)\n",
    "\n",
    "print(\"Rows:\", rows)\n",
    "print(\"Cols:\", cols)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb91187-1ede-4417-9d0b-7539c1b71c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc75d4-a027-4cba-a641-df48bf9787c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fedad41-bc70-4381-a337-c7679576b808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a3d53-f5d6-43d6-ac90-a8a9df92921d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
